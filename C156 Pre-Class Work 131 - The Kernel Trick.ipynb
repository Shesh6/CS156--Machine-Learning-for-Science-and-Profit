{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C156PW131.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "KZmll_zTMPwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CS156 Pre-Class Work for Session 13.1\n",
        "\n",
        "#### Kernel Trick"
      ]
    },
    {
      "metadata": {
        "id": "C66Jf7d_Q6_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the gradients for the following activations:\n",
        "\n",
        "1. Linear\n",
        "\n",
        "    *A = cx*\n",
        "\n",
        "    Gradient:  *A' = c*\n",
        "\n",
        "2. Rectified Linear Unit (aka RelU)\n",
        "\n",
        "    *A(x) = max(0, x)*\n",
        "\n",
        "    Gradient: \n",
        "\n",
        "    0 for x < 0 and\n",
        "\n",
        "    1 for x > 0 \n",
        "\n",
        "    gives an output x if x is positive and 0 otherwise\n",
        "\n",
        "3. Sigmoid\n",
        "\n",
        "    *A = 1/(1 + e^(-x))*\n",
        "\n",
        "    Gradient: \n",
        "\n",
        "    $$A' = \\frac{\\partial}{\\partial x}(\\frac{1}{1 + e^{-x}})$$\n",
        "\n",
        "    $$= \\frac{e^{-x}}{(1+ e^{-x})^2}$$\n",
        "\n",
        "    $$= \\frac{1 + e^{-x}-1}{(1+e^{-x})^2}$$\n",
        "\n",
        "    $$= \\frac{1 + e^{-x}}{(1+e^{-x})^2} - (\\frac{1}{1 + e^{-x}})^2$$\n",
        "\n",
        "    $$= \\frac{1}{(1+e^{-x})} - (\\frac{1}{1 + e^{-x}})^2$$\n",
        "\n",
        "    $$= A - A^2$$\n",
        "\n",
        "    $$= A(1 - A)$$"
      ]
    },
    {
      "metadata": {
        "id": "vM8pl5iYQ0Ca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Michaliav\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EIM3rDnQ0Cg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter = \",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fG_ihG2PQ0Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0YbD2DqQ0Cp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kr_d2uejQ0Ct",
        "colab_type": "code",
        "outputId": "529d1152-01df-4e33-e4f8-c3d798260967",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 1.0972 - acc: 0.5872\n",
            "Epoch 2/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.7484 - acc: 0.6159\n",
            "Epoch 3/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6884 - acc: 0.6107\n",
            "Epoch 4/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6698 - acc: 0.6406\n",
            "Epoch 5/150\n",
            "768/768 [==============================] - ETA: 0s - loss: 0.6427 - acc: 0.628 - 2s 2ms/step - loss: 0.6397 - acc: 0.6328\n",
            "Epoch 6/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6272 - acc: 0.6576\n",
            "Epoch 7/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6254 - acc: 0.6628\n",
            "Epoch 8/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6309 - acc: 0.6510\n",
            "Epoch 9/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6223 - acc: 0.6680\n",
            "Epoch 10/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6195 - acc: 0.6654\n",
            "Epoch 11/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6287 - acc: 0.6693\n",
            "Epoch 12/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6128 - acc: 0.6849\n",
            "Epoch 13/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6232 - acc: 0.6693\n",
            "Epoch 14/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6125 - acc: 0.6732\n",
            "Epoch 15/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6161 - acc: 0.6784\n",
            "Epoch 16/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5992 - acc: 0.6888\n",
            "Epoch 17/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5966 - acc: 0.6927\n",
            "Epoch 18/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.6091 - acc: 0.6693\n",
            "Epoch 19/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5944 - acc: 0.6901\n",
            "Epoch 20/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5766 - acc: 0.7083\n",
            "Epoch 21/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5850 - acc: 0.7018\n",
            "Epoch 22/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5933 - acc: 0.6719\n",
            "Epoch 23/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5862 - acc: 0.7031\n",
            "Epoch 24/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5823 - acc: 0.7018\n",
            "Epoch 25/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5755 - acc: 0.7161\n",
            "Epoch 26/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5772 - acc: 0.6979\n",
            "Epoch 27/150\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.5682 - acc: 0.7096\n",
            "Epoch 28/150\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.5622 - acc: 0.7370\n",
            "Epoch 29/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5840 - acc: 0.7070\n",
            "Epoch 30/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5716 - acc: 0.7109A: 1s - lo\n",
            "Epoch 31/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5785 - acc: 0.7044\n",
            "Epoch 32/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5656 - acc: 0.7174\n",
            "Epoch 33/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5560 - acc: 0.7214\n",
            "Epoch 34/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5607 - acc: 0.7279\n",
            "Epoch 35/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5612 - acc: 0.7174\n",
            "Epoch 36/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5670 - acc: 0.7174\n",
            "Epoch 37/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5434 - acc: 0.7383\n",
            "Epoch 38/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5490 - acc: 0.7292\n",
            "Epoch 39/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5574 - acc: 0.7370\n",
            "Epoch 40/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5503 - acc: 0.7279\n",
            "Epoch 41/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5486 - acc: 0.7214\n",
            "Epoch 42/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5467 - acc: 0.7174\n",
            "Epoch 43/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5484 - acc: 0.7357\n",
            "Epoch 44/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5387 - acc: 0.7409\n",
            "Epoch 45/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5372 - acc: 0.7487A: 1s - los\n",
            "Epoch 46/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5430 - acc: 0.7409\n",
            "Epoch 47/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5355 - acc: 0.7383\n",
            "Epoch 48/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5460 - acc: 0.7370\n",
            "Epoch 49/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5348 - acc: 0.7500\n",
            "Epoch 50/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5355 - acc: 0.7474\n",
            "Epoch 51/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5333 - acc: 0.7409\n",
            "Epoch 52/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5377 - acc: 0.7383\n",
            "Epoch 53/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5350 - acc: 0.7474\n",
            "Epoch 54/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5459 - acc: 0.7305A: 0s - loss: 0.5458 - acc: 0.\n",
            "Epoch 55/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5261 - acc: 0.7552\n",
            "Epoch 56/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5383 - acc: 0.7422\n",
            "Epoch 57/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5336 - acc: 0.7383\n",
            "Epoch 58/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5281 - acc: 0.7435\n",
            "Epoch 59/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5206 - acc: 0.7422\n",
            "Epoch 60/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5400 - acc: 0.7422\n",
            "Epoch 61/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5221 - acc: 0.7305\n",
            "Epoch 62/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5208 - acc: 0.7500\n",
            "Epoch 63/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5449 - acc: 0.7396\n",
            "Epoch 64/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5336 - acc: 0.7331\n",
            "Epoch 65/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5186 - acc: 0.7513\n",
            "Epoch 66/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5191 - acc: 0.7435\n",
            "Epoch 67/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5271 - acc: 0.7461\n",
            "Epoch 68/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5191 - acc: 0.7357\n",
            "Epoch 69/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5221 - acc: 0.7292\n",
            "Epoch 70/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5372 - acc: 0.7227\n",
            "Epoch 71/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5252 - acc: 0.7461\n",
            "Epoch 72/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5261 - acc: 0.7617\n",
            "Epoch 73/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5168 - acc: 0.7487\n",
            "Epoch 74/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5131 - acc: 0.7500\n",
            "Epoch 75/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5121 - acc: 0.7552\n",
            "Epoch 76/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5125 - acc: 0.7487\n",
            "Epoch 77/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5191 - acc: 0.7552\n",
            "Epoch 78/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5191 - acc: 0.7409\n",
            "Epoch 79/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5218 - acc: 0.7591\n",
            "Epoch 80/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5076 - acc: 0.7604\n",
            "Epoch 81/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5076 - acc: 0.7604\n",
            "Epoch 82/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5062 - acc: 0.7435\n",
            "Epoch 83/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5094 - acc: 0.7500\n",
            "Epoch 84/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4988 - acc: 0.7552\n",
            "Epoch 85/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5091 - acc: 0.7630\n",
            "Epoch 86/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5145 - acc: 0.7500\n",
            "Epoch 87/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5030 - acc: 0.7552\n",
            "Epoch 88/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4981 - acc: 0.7643\n",
            "Epoch 89/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5056 - acc: 0.7708\n",
            "Epoch 90/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5148 - acc: 0.7539\n",
            "Epoch 91/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5004 - acc: 0.7578\n",
            "Epoch 92/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5165 - acc: 0.7305\n",
            "Epoch 93/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4958 - acc: 0.7565\n",
            "Epoch 94/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4983 - acc: 0.7617\n",
            "Epoch 95/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5014 - acc: 0.7422\n",
            "Epoch 96/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4916 - acc: 0.7656\n",
            "Epoch 97/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4911 - acc: 0.7813\n",
            "Epoch 98/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4903 - acc: 0.7669\n",
            "Epoch 99/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4967 - acc: 0.7604\n",
            "Epoch 100/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4900 - acc: 0.7695\n",
            "Epoch 101/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4944 - acc: 0.7617\n",
            "Epoch 102/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5046 - acc: 0.7513\n",
            "Epoch 103/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4997 - acc: 0.7643\n",
            "Epoch 104/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5042 - acc: 0.7630A: 0s - loss: 0.5153 - acc:\n",
            "Epoch 105/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5157 - acc: 0.7604\n",
            "Epoch 106/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4925 - acc: 0.7708\n",
            "Epoch 107/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4965 - acc: 0.7695\n",
            "Epoch 108/150\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.5035 - acc: 0.7578\n",
            "Epoch 109/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4949 - acc: 0.7552\n",
            "Epoch 110/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4985 - acc: 0.7539\n",
            "Epoch 111/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4903 - acc: 0.7669\n",
            "Epoch 112/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4960 - acc: 0.7578\n",
            "Epoch 113/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5029 - acc: 0.7578\n",
            "Epoch 114/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5014 - acc: 0.7526\n",
            "Epoch 115/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4952 - acc: 0.7643\n",
            "Epoch 116/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5034 - acc: 0.7617\n",
            "Epoch 117/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4956 - acc: 0.7643\n",
            "Epoch 118/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4890 - acc: 0.7747\n",
            "Epoch 119/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4892 - acc: 0.7734A: 0s - loss: 0.4826 - \n",
            "Epoch 120/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4975 - acc: 0.7747\n",
            "Epoch 121/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4899 - acc: 0.7812\n",
            "Epoch 122/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4950 - acc: 0.7617\n",
            "Epoch 123/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4863 - acc: 0.7591\n",
            "Epoch 124/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4829 - acc: 0.7747\n",
            "Epoch 125/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4932 - acc: 0.7760\n",
            "Epoch 126/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4843 - acc: 0.7799\n",
            "Epoch 127/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4931 - acc: 0.7487\n",
            "Epoch 128/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4791 - acc: 0.7643\n",
            "Epoch 129/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4852 - acc: 0.7617\n",
            "Epoch 130/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4800 - acc: 0.7760\n",
            "Epoch 131/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4911 - acc: 0.7422\n",
            "Epoch 132/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4908 - acc: 0.7708\n",
            "Epoch 133/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4926 - acc: 0.7591\n",
            "Epoch 134/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4915 - acc: 0.7565\n",
            "Epoch 135/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4803 - acc: 0.7682\n",
            "Epoch 136/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4784 - acc: 0.7682\n",
            "Epoch 137/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4757 - acc: 0.7865\n",
            "Epoch 138/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4819 - acc: 0.7826\n",
            "Epoch 139/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4775 - acc: 0.7617\n",
            "Epoch 140/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4777 - acc: 0.7773\n",
            "Epoch 141/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4801 - acc: 0.7721\n",
            "Epoch 142/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4892 - acc: 0.7578\n",
            "Epoch 143/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4820 - acc: 0.7695\n",
            "Epoch 144/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4793 - acc: 0.7695\n",
            "Epoch 145/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.5095 - acc: 0.7448\n",
            "Epoch 146/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4881 - acc: 0.7552\n",
            "Epoch 147/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4922 - acc: 0.7539\n",
            "Epoch 148/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4749 - acc: 0.7747\n",
            "Epoch 149/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4877 - acc: 0.7604\n",
            "Epoch 150/150\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 0.4813 - acc: 0.7656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x15af5e031d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Z44Ul3gxQ0C2",
        "colab_type": "code",
        "outputId": "233a2e95-0a35-4604-b3ed-c4ced8691b81",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 0s 384us/step\n",
            "\n",
            "acc: 77.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q21-hB14Q0C9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate predictions\n",
        "predictions = model.predict(X)\n",
        "# round predictions\n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "#print(rounded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_HI2VXgQ0DE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "(moon_x,moon_y) = datasets.make_moons(n_samples=10000, noise=0.05, random_state=42)\n",
        "\n",
        "(circle_x,circle_y) = datasets.make_circles(n_samples=10000, noise=0.025, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZQknO-IQ0DK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    \"\"\"Create a mesh of points to plot in\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x: data to base x-axis meshgrid on\n",
        "    y: data to base y-axis meshgrid on\n",
        "    h: stepsize for meshgrid, optional\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    xx, yy : ndarray\n",
        "    \"\"\"\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    \"\"\"Plot the decision boundaries for a classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ax: matplotlib axes object\n",
        "    clf: a classifier\n",
        "    xx: meshgrid ndarray\n",
        "    yy: meshgrid ndarray\n",
        "    params: dictionary of params to pass to contourf, optional\n",
        "    \"\"\"\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0w64J_OQ0DQ",
        "colab_type": "code",
        "outputId": "ac19bce7-d304-410e-a734-0eacbd059046",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X0, X1 = moon_x[:, 0], moon_x[:, 1]\n",
        "xx, yy = make_meshgrid(X0, X1)\n",
        "\n",
        "# create model\n",
        "moon_model = Sequential()\n",
        "moon_model.add(Dense(12, input_dim=2, activation=\"relu\"))\n",
        "moon_model.add(Dense(8, activation=\"relu\"))\n",
        "moon_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# compile model\n",
        "moon_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "moon_model.fit(moon_x, moon_y, epochs=150, batch_size=10)\n",
        "\n",
        "# evaluate the model\n",
        "moon_scores = moon_model.evaluate(moon_x, moon_y)\n",
        "print(\"\\n%s: %.2f%%\" % (moon_model.metrics_names[1], moon_scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 0.3368 - acc: 0.8451\n",
            "Epoch 2/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 0.1674 - acc: 0.9226\n",
            "Epoch 3/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 0.0956 - acc: 0.9576\n",
            "Epoch 4/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0487 - acc: 0.9831\n",
            "Epoch 5/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0222 - acc: 0.9973\n",
            "Epoch 6/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 7/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 8/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 9/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 10/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 8.8062e-04 - acc: 1.0000\n",
            "Epoch 11/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 5.2866e-04 - acc: 1.0000\n",
            "Epoch 12/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 3.2188e-04 - acc: 1.0000\n",
            "Epoch 13/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.9708e-04 - acc: 1.0000\n",
            "Epoch 14/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.2430e-04 - acc: 1.0000\n",
            "Epoch 15/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 8.6786e-05 - acc: 1.0000\n",
            "Epoch 16/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 5.2506e-05 - acc: 1.0000\n",
            "Epoch 17/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 3.7348e-05 - acc: 1.0000\n",
            "Epoch 18/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 2.6443e-05 - acc: 1.0000\n",
            "Epoch 19/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 1.7447e-05 - acc: 1.0000\n",
            "Epoch 20/150\n",
            "10000/10000 [==============================] - 22s 2ms/step - loss: 1.1355e-05 - acc: 1.0000\n",
            "Epoch 21/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 9.2389e-06 - acc: 1.0000\n",
            "Epoch 22/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 6.6153e-06 - acc: 1.0000\n",
            "Epoch 23/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 5.8178e-06 - acc: 1.0000\n",
            "Epoch 24/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 3.4647e-06 - acc: 1.0000\n",
            "Epoch 25/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 3.4331e-06 - acc: 1.0000\n",
            "Epoch 26/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.2508e-06 - acc: 1.0000\n",
            "Epoch 27/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.7613e-06 - acc: 1.0000\n",
            "Epoch 28/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.3395e-06 - acc: 1.0000\n",
            "Epoch 29/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.2740e-06 - acc: 1.0000\n",
            "Epoch 30/150\n",
            "10000/10000 [==============================] - 23s 2ms/step - loss: 7.1067e-07 - acc: 1.0000\n",
            "Epoch 31/150\n",
            "10000/10000 [==============================] - 23s 2ms/step - loss: 8.1547e-07 - acc: 1.0000\n",
            "Epoch 32/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 6.2135e-07 - acc: 1.0000\n",
            "Epoch 33/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 6.5398e-07 - acc: 1.0000\n",
            "Epoch 34/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 3.7280e-07 - acc: 1.0000\n",
            "Epoch 35/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.3831e-06 - acc: 1.0000\n",
            "Epoch 36/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 3.4252e-07 - acc: 1.0000\n",
            "Epoch 37/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 2.6759e-07 - acc: 1.0000\n",
            "Epoch 38/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3133e-07 - acc: 1.0000\n",
            "Epoch 39/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.4900e-07 - acc: 1.0000\n",
            "Epoch 40/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 4.1993e-07 - acc: 1.0000\n",
            "Epoch 41/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.2604e-07 - acc: 1.0000\n",
            "Epoch 42/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.0983e-07 - acc: 1.0000\n",
            "Epoch 43/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.8659e-07 - acc: 1.0000\n",
            "Epoch 44/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 2.1013e-07 - acc: 1.0000\n",
            "Epoch 45/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.3489e-07 - acc: 1.0000\n",
            "Epoch 46/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.4409e-07 - acc: 1.0000\n",
            "Epoch 47/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.4198e-07 - acc: 1.0000\n",
            "Epoch 48/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.5035e-07 - acc: 1.0000\n",
            "Epoch 49/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.3923e-07 - acc: 1.0000\n",
            "Epoch 50/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.3669e-07 - acc: 1.0000\n",
            "Epoch 51/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.5132e-07 - acc: 1.0000\n",
            "Epoch 52/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.3244e-07 - acc: 1.0000\n",
            "Epoch 53/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.2066e-07 - acc: 1.0000\n",
            "Epoch 54/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.2324e-07 - acc: 1.0000\n",
            "Epoch 55/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.0119e-06 - acc: 1.0000\n",
            "Epoch 56/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 2.9795e-07 - acc: 1.0000\n",
            "Epoch 57/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.2297e-07 - acc: 1.0000\n",
            "Epoch 58/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1823e-07 - acc: 1.0000\n",
            "Epoch 59/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1698e-07 - acc: 1.0000\n",
            "Epoch 60/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1583e-07 - acc: 1.0000\n",
            "Epoch 61/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1552e-07 - acc: 1.0000\n",
            "Epoch 62/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 1.1484e-07 - acc: 1.0000\n",
            "Epoch 63/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1856e-07 - acc: 1.0000\n",
            "Epoch 64/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1299e-07 - acc: 1.0000\n",
            "Epoch 65/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1322e-07 - acc: 1.0000\n",
            "Epoch 66/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1281e-07 - acc: 1.0000\n",
            "Epoch 67/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 2.7803e-07 - acc: 1.0000\n",
            "Epoch 68/150\n",
            "10000/10000 [==============================] - 27s 3ms/step - loss: 1.1598e-07 - acc: 1.0000\n",
            "Epoch 69/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1223e-07 - acc: 1.0000\n",
            "Epoch 70/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1153e-07 - acc: 1.0000\n",
            "Epoch 71/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1146e-07 - acc: 1.0000\n",
            "Epoch 72/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1207e-07 - acc: 1.0000\n",
            "Epoch 73/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 5.3103e-07 - acc: 1.0000\n",
            "Epoch 74/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 3.1142e-07 - acc: 1.0000\n",
            "Epoch 75/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.2141e-07 - acc: 1.0000\n",
            "Epoch 76/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1277e-07 - acc: 1.0000\n",
            "Epoch 77/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1213e-07 - acc: 1.0000\n",
            "Epoch 78/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1153e-07 - acc: 1.0000\n",
            "Epoch 79/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1143e-07 - acc: 1.0000\n",
            "Epoch 80/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1182e-07 - acc: 1.0000\n",
            "Epoch 81/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1076e-07 - acc: 1.0000\n",
            "Epoch 82/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1100e-07 - acc: 1.0000\n",
            "Epoch 83/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1145e-07 - acc: 1.0000\n",
            "Epoch 84/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1096e-07 - acc: 1.0000\n",
            "Epoch 85/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1096e-07 - acc: 1.0000\n",
            "Epoch 86/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.8252e-07 - acc: 1.0000\n",
            "Epoch 87/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 5.1135e-07 - acc: 1.0000\n",
            "Epoch 88/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1536e-07 - acc: 1.0000\n",
            "Epoch 89/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1273e-07 - acc: 1.0000\n",
            "Epoch 90/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1160e-07 - acc: 1.0000\n",
            "Epoch 91/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1096e-07 - acc: 1.0000\n",
            "Epoch 92/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1063e-07 - acc: 1.0000\n",
            "Epoch 93/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.1049e-07 - acc: 1.0000\n",
            "Epoch 94/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1035e-07 - acc: 1.0000\n",
            "Epoch 95/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1027e-07 - acc: 1.0000\n",
            "Epoch 96/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1030e-07 - acc: 1.0000\n",
            "Epoch 97/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1031e-07 - acc: 1.0000\n",
            "Epoch 98/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1056e-07 - acc: 1.0000\n",
            "Epoch 99/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1040e-07 - acc: 1.0000\n",
            "Epoch 100/150\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 1.1050e-07 - acc: 1.0000\n",
            "Epoch 101/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1571e-07 - acc: 1.0000\n",
            "Epoch 102/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.2263e-07 - acc: 1.0000\n",
            "Epoch 103/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.1009e-07 - acc: 1.0000\n",
            "Epoch 104/150\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 1.0993e-07 - acc: 1.0000\n",
            "Epoch 105/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.0993e-07 - acc: 1.0000\n",
            "Epoch 106/150\n",
            "10000/10000 [==============================] - 19s 2ms/step - loss: 1.0981e-07 - acc: 1.0000\n",
            "Epoch 107/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.0992e-07 - acc: 1.0000\n",
            "Epoch 108/150\n",
            "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1006e-07 - acc: 1.0000\n",
            "Epoch 109/150\n",
            "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3678e-07 - acc: 1.0000\n",
            "Epoch 110/150\n",
            "  910/10000 [=>............................] - ETA: 18s - loss: 1.0950e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQofFOI7Q0DW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_contours(plt, clf, xx, yy, cmap='viridis', alpha=0.8)\n",
        "\n",
        "\n",
        "plt.scatter(X0, X1, c=moon_y, cmap='viridis', s=5, linewidths=0)\n",
        "\n",
        "plt.set_xlim(xx.min(), xx.max())\n",
        "plt.set_ylim(yy.min(), yy.max())\n",
        "plt.set_xticks(())\n",
        "plt.set_yticks(())\n",
        "plt.set_title('moon model')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}