{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS156 Assignment 4.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fTRUXl3xIHUr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###CS156 Assignment 4: MNIST Digits\n",
        "_Yoav Rabinovich, Oct 2018_\n",
        "\n",
        "-------------------------"
      ]
    },
    {
      "metadata": {
        "id": "gowrj5MHGrLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this assignment, the instructions were vauge on whether we should train a classifier for two digits, or plot the two digits and do multiclass classification for the rest of the assignment. I chose the latter (albeit less likely), so that I can get an opportunity to talk about multiclass classification. This has vastly (see below) lengthened training times, so I trained on 50% of the dataset by sampling randomly from the original.\n",
        "\n",
        "__Multiclass Classification by solving multiple binary classification problems__\n",
        "\n",
        "Multiclass classification is usually handeled by creating several binary classifiers and aggragating their results. The two prevalent methods are called \"One vs One\" and \"One vs Rest\". Other strategies and other methods that are used today, but I focus on the most popular.\n",
        "\n",
        "__One vs One__\n",
        "\n",
        "In OvO multiclass classification, a classifier is built for every pair in the output space, classifying, for out purposes, every number into either a 1 or a 2, then into either a 1 or a 3 and so on.  This results in building $\\frac{K(K-1)}{2}$ separate classifiers, where $K$ is the size of the output space, each trained on the relevant samples from the training data. When a test sample is introduced, each classifier casts a vote and the class most voted for is picked. In our case, hopefully all 9 classifiers associated with the digit 1 vote for 1 when a test 1 is seen, where no other number will get similar success. The classifiers associated with 7 might all vote 7, save the 7-1 classifier, which would turn the tide. If it doesn't, OvO classification can run into ties, usually broken randomly.\n",
        "\n",
        "__One vs Rest__\n",
        "\n",
        "In OvR multiclass classification, only $K$ classifiers are needed, one per output class. Each classifier is trained on the entire dataset, relabling all classes but one as \"rest\", and distinguishing the chosen class from any of them. While this drastically lowers the number of classifiers, voting is clearly not a strong enough decision function for the problem with only $K$ voters. For this reason, OvR emplys classifiers that output a confidence level, and chooses the class who's classifier outputs the strongest confidence for a given test sample. For a 1 sample, we would hoe the 1 classifier outputs for example a confidence of 0.97, while the 7 classifier would output 0.84. However, the classifiers are trained with a large number of negative samples by design, which would lead to a hard bias for negative classification. Additionally, the hidden assumption that all classifiers would behave similarly with regards to variance ad mean in output confidence levels, that might not be the case, and a strong classification for 7, say 0.9, might actually correspond to a lower number for the 1 classifier, say 0.8, leading to a bias towards high-variance classifiers in the final decision.\n",
        "\n",
        "SKLearn's SVC method uses One vs One for multiclass classification. This meant that for all 63 fits computed in my grid search over kernels, kernel parameters and error penalty parameters, $\\frac{10(9)}{2}=45$ classifiers were trained, resulting in  2,835 fits overall. For this reason I used only 50% of the dataset for training, as described above, and still the training took 2 hours. My computer crashed while I was working, and so the final part reporting times and error is done with information from a previous run with 25,000 samples."
      ]
    },
    {
      "metadata": {
        "id": "2NKyhQgLmMcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from shutil import copyfileobj\n",
        "from six.moves import urllib\n",
        "from sklearn.datasets.base import get_data_home\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4IqtHmZlIS_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import dataset (From Slack)\n",
        "\n",
        "def fetch_mnist(data_home=None):\n",
        "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
        "    data_home = get_data_home(data_home=data_home)\n",
        "    data_home = os.path.join(data_home, 'mldata')\n",
        "    if not os.path.exists(data_home):\n",
        "        os.makedirs(data_home)\n",
        "    mnist_save_path = os.path.join(data_home, \"mnist-original.mat\")\n",
        "    if not os.path.exists(mnist_save_path):\n",
        "        mnist_url = urllib.request.urlopen(mnist_alternative_url)\n",
        "        with open(mnist_save_path, \"wb\") as matlab_file:\n",
        "            copyfileobj(mnist_url, matlab_file)\n",
        "\n",
        "fetch_mnist()\n",
        "mnist = fetch_mldata(\"MNIST original\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEWpGeyDolZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert to Pandas Dataframe\n",
        "digits = pd.DataFrame(index=range(len(mnist[\"data\"])),columns=[\"data\",\"label\"])\n",
        "digits[\"data\"] = pd.Series(list(mnist[\"data\"]))\n",
        "digits[\"label\"]=pd.Series(mnist[\"target\"])\n",
        "# Take randomized subset to optimize training time\n",
        "size = 35000\n",
        "digits = digits.sample(size)\n",
        "digits = digits.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOKR19siI_XX",
        "colab_type": "code",
        "outputId": "485ab8a9-3883-4861-a4ca-a4c251f16285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "cell_type": "code",
      "source": [
        "# Plotting sample pictures of my favorite digits\n",
        "\n",
        "# Collect examples\n",
        "sixs = []\n",
        "# Confuse your enemies\n",
        "nines = []\n",
        "for i in range(len(digits[\"data\"])):\n",
        "  if (digits[\"label\"][i]==6) and (len(sixs)<6):\n",
        "    pixels = digits[\"data\"][i].reshape((28, 28))\n",
        "    sixs.append(pixels)\n",
        "  if (digits[\"label\"][i]==8) and (len(nines)<6):\n",
        "    pixels = digits[\"data\"][i].reshape((28, 28))\n",
        "    nines.append(pixels)\n",
        "  if len(sixs)+len(nines)==11:\n",
        "    break\n",
        "    \n",
        "# Plot examples, but not as if they're written in chalk because that's boring\n",
        "for i in range(5):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(sixs[i],cmap=\"Oranges\")\n",
        "  plt.axis('off')\n",
        "  plt.subplot(2,5,i+6)\n",
        "  plt.imshow(nines[i],cmap=\"Blues\")\n",
        "  plt.axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAESCAYAAAC8dt8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9ad719048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ixjrjHKNJJv8",
        "colab_type": "code",
        "outputId": "76655e43-9ec6-4956-919d-fc7050402798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "cell_type": "code",
      "source": [
        "# SVM Kernel Comparison\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.vstack(digits[\"data\"]), digits[\"label\"], test_size=0.2)\n",
        "\n",
        "# Gridsearch over kernel, C, degree and gamma\n",
        "param_grids = [\n",
        "    {'kernel': ['linear'], 'C': [1, 10, 100]},\n",
        "    {'kernel': ['poly'], 'C': [1, 10, 100], 'degree': [2,3,4]},\n",
        "    {'kernel': ['rbf'], 'C': [1, 10, 100],'gamma': [10**-9,10**-8,10**-7]}\n",
        "]\n",
        "search = GridSearchCV(SVC(), param_grids, cv=3, n_jobs=-1, verbose=49, iid=True, return_train_score = False) # Setting some parameters to their default values to avoid some deprecation warnings\n",
        "search.fit(X_train, y_train)\n",
        "# Print best estimator parameters\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "print(search.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-08, kernel=rbf, score=0.9183542269366763, total= 6.7min\n",
            "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 74.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-09, kernel=rbf, score=0.8543564462544208, total=15.0min\n",
            "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 74.9min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-07, kernel=rbf, score=0.9581191088260497, total= 3.5min\n",
            "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 78.5min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-08, kernel=rbf, score=0.9138356017575823, total= 6.6min\n",
            "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 81.5min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-07, kernel=rbf, score=0.9553198328511733, total= 3.5min\n",
            "[CV] C=10, gamma=1e-09, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 81.9min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1, gamma=1e-07, kernel=rbf, score=0.9545600685885757, total= 3.6min\n",
            "[CV] C=10, gamma=1e-09, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 85.1min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-09, kernel=rbf, score=0.918808911739503, total= 6.4min\n",
            "[CV] C=10, gamma=1e-09, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 88.4min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-09, kernel=rbf, score=0.9172827600985749, total= 6.6min\n",
            "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 91.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-09, kernel=rbf, score=0.9121208873646983, total= 6.3min\n",
            "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 94.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-08, kernel=rbf, score=0.9405526992287918, total= 3.4min\n",
            "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 95.0min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-08, kernel=rbf, score=0.9364620165005894, total= 3.2min\n",
            "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 97.9min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-08, kernel=rbf, score=0.9373057550101811, total= 3.4min\n",
            "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 98.4min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-07, kernel=rbf, score=0.9686161096829478, total= 2.8min\n",
            "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 100.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-07, kernel=rbf, score=0.9683917282760098, total= 2.9min\n",
            "[CV] C=100, gamma=1e-09, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 101.3min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10, gamma=1e-07, kernel=rbf, score=0.969456649876755, total= 2.7min\n",
            "[CV] C=100, gamma=1e-09, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 103.4min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-09, kernel=rbf, score=0.9355184233076264, total= 3.4min\n",
            "[CV] C=100, gamma=1e-09, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 104.6min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-09, kernel=rbf, score=0.9334619093539055, total= 3.2min\n",
            "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 106.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-09, kernel=rbf, score=0.9326974600793055, total= 3.3min\n",
            "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 107.9min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-08, kernel=rbf, score=0.9484790059982862, total= 2.5min\n",
            "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 109.1min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-08, kernel=rbf, score=0.9457837779920711, total= 2.5min\n",
            "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 110.5min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-08, kernel=rbf, score=0.9456649876754903, total= 2.4min\n",
            "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 111.6min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=100, gamma=1e-07, kernel=rbf, score=0.9701156812339332, total= 2.8min\n",
            "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
            "[CV]  C=100, gamma=1e-07, kernel=rbf, score=0.9692489017464909, total= 2.8min\n",
            "[CV]  C=100, gamma=1e-07, kernel=rbf, score=0.9703140070731968, total= 2.7min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed: 116.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=0.970):\n",
            "{'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZBVvG19NJxmu",
        "colab_type": "code",
        "outputId": "a5d1c6cc-e9a5-45c3-8c2f-f733f54167ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "cell_type": "code",
      "source": [
        "# Print classification report for best estimator\n",
        "print(classification_report(y_test,search.best_estimator_.predict(X_test)))\n",
        "print(confusion_matrix(y_test,search.best_estimator_.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.98      0.98      0.98       675\n",
            "        1.0       0.99      1.00      0.99       815\n",
            "        2.0       0.95      0.98      0.97       683\n",
            "        3.0       0.96      0.96      0.96       740\n",
            "        4.0       0.97      0.98      0.97       654\n",
            "        5.0       0.97      0.97      0.97       634\n",
            "        6.0       0.98      0.99      0.99       684\n",
            "        7.0       0.98      0.97      0.98       744\n",
            "        8.0       0.98      0.96      0.97       636\n",
            "        9.0       0.97      0.96      0.97       735\n",
            "\n",
            "avg / total       0.97      0.97      0.97      7000\n",
            "\n",
            "[[663   1   5   1   1   1   1   0   2   0]\n",
            " [  1 811   0   1   0   0   0   1   0   1]\n",
            " [  1   0 668   4   3   2   0   3   2   0]\n",
            " [  1   1  10 708   0   9   0   5   3   3]\n",
            " [  0   1   4   0 638   0   2   0   0   9]\n",
            " [  1   0   4   8   0 613   4   1   1   2]\n",
            " [  4   0   0   0   1   1 678   0   0   0]\n",
            " [  1   2   6   0   7   0   0 723   1   4]\n",
            " [  2   3   4   6   3   2   4   0 608   4]\n",
            " [  0   2   0   8   7   2   0   6   3 707]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EbKq57GQqT7v",
        "colab_type": "code",
        "outputId": "c8c15ce5-3547-4432-f707-2ec8bd3ff62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1062
        }
      },
      "cell_type": "code",
      "source": [
        "# Collect result data\n",
        "results = pd.DataFrame(search.cv_results_)\n",
        "\n",
        "\n",
        "# Report average training times for each kernel\n",
        "lin_times=[]\n",
        "pol_times=[]\n",
        "rbf_times=[]\n",
        "best_times=[0,0,0]\n",
        "best_est=[None,None,None]\n",
        "for row in results.iterrows():\n",
        "  if row[1][5]=='linear':\n",
        "    lin_times.append(row[1][0])\n",
        "    if row[1][12]>best_times[0]:\n",
        "      best_times[0] = row[1][12]\n",
        "      best_est[0]=row[1][8]\n",
        "  if row[1][5]=='poly':\n",
        "    pol_times.append(row[1][0])\n",
        "    if row[1][12]>best_times[1]:\n",
        "      best_times[1] = row[1][12]\n",
        "      best_est[1]=row[1][8]\n",
        "  if row[1][5]=='rbf':\n",
        "    rbf_times.append(row[1][0])\n",
        "    if row[1][12]>best_times[2]:\n",
        "      best_times[2] = row[1][12]\n",
        "      best_est[2]=row[1][8]\n",
        "    \n",
        "print(\"Mean Training Times:\")\n",
        "print(\"Linear Kernel: \" + str(sum(lin_times)/len(lin_times)) + \" seconds.\")\n",
        "print(\"Polynomial Kernel: \" + str(sum(pol_times)/len(pol_times)) + \" seconds.\")\n",
        "print(\"Radial Basis Function Kernel: \" + str(sum(rbf_times)/len(rbf_times)) + \" seconds.\")\n",
        "\n",
        "# Report error on test set with classification report, for best estimator of each kernel\n",
        "lin_est=SVC(kernel='linear',C=best_est[0][\"C\"]).fit(X_train,y_train)\n",
        "lin_pred=lin_est.predict(X_test)\n",
        "pol_est=SVC(kernel='poly',C=best_est[1][\"C\"],degree=best_est[1][\"degree\"]).fit(X_train,y_train)\n",
        "pol_pred=lin_est.predict(X_test)\n",
        "rbf_est=SVC(kernel='rbf',C=best_est[2][\"C\"],gamma=best_est[2][\"gamma\"]).fit(X_train,y_train)\n",
        "rbf_pred=lin_est.predict(X_test)\n",
        "\n",
        "print(\"Classification Reports:\")\n",
        "print(\"Linear Kernel:\")\n",
        "print(classification_report(y_test,lin_pred))\n",
        "print(\"Polynomial Kernel:\")\n",
        "print(classification_report(y_test,pol_pred))\n",
        "print(\"Radial Basis Function Kernel:\")\n",
        "print(classification_report(y_test,rbf_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Training Times:\n",
            "Linear Kernel: 63.99365679423014 seconds.\n",
            "Polynomial Kernel: 82.97143636809454 seconds.\n",
            "Radial Basis Function Kernel: 155.04097125265332 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rabin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification Reports:\n",
            "Linear Kernel:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94       497\n",
            "         1.0       0.95      0.98      0.96       519\n",
            "         2.0       0.86      0.90      0.88       470\n",
            "         3.0       0.85      0.88      0.87       523\n",
            "         4.0       0.90      0.95      0.92       498\n",
            "         5.0       0.86      0.88      0.87       445\n",
            "         6.0       0.95      0.93      0.94       478\n",
            "         7.0       0.93      0.92      0.92       558\n",
            "         8.0       0.92      0.81      0.86       478\n",
            "         9.0       0.91      0.84      0.87       534\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      5000\n",
            "   macro avg       0.91      0.90      0.90      5000\n",
            "weighted avg       0.91      0.91      0.91      5000\n",
            "\n",
            "Polynomial Kernel:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94       497\n",
            "         1.0       0.95      0.98      0.96       519\n",
            "         2.0       0.86      0.90      0.88       470\n",
            "         3.0       0.85      0.88      0.87       523\n",
            "         4.0       0.90      0.95      0.92       498\n",
            "         5.0       0.86      0.88      0.87       445\n",
            "         6.0       0.95      0.93      0.94       478\n",
            "         7.0       0.93      0.92      0.92       558\n",
            "         8.0       0.92      0.81      0.86       478\n",
            "         9.0       0.91      0.84      0.87       534\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      5000\n",
            "   macro avg       0.91      0.90      0.90      5000\n",
            "weighted avg       0.91      0.91      0.91      5000\n",
            "\n",
            "Radial Basis Function Kernel:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94       497\n",
            "         1.0       0.95      0.98      0.96       519\n",
            "         2.0       0.86      0.90      0.88       470\n",
            "         3.0       0.85      0.88      0.87       523\n",
            "         4.0       0.90      0.95      0.92       498\n",
            "         5.0       0.86      0.88      0.87       445\n",
            "         6.0       0.95      0.93      0.94       478\n",
            "         7.0       0.93      0.92      0.92       558\n",
            "         8.0       0.92      0.81      0.86       478\n",
            "         9.0       0.91      0.84      0.87       534\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      5000\n",
            "   macro avg       0.91      0.90      0.90      5000\n",
            "weighted avg       0.91      0.91      0.91      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "autQdPvvJLwc",
        "colab_type": "code",
        "outputId": "1ee03110-5c1b-4a9c-ffc2-d2c1c52f4f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "4bsOo0R12hmq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}