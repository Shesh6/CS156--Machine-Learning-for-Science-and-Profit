{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS156 Assignment 2\n",
    "_Yoav Rabinovich, July 2018_\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will crease a random forest classifier to distinguish between rejected and accepted loan requests based on features of the requests and the requesting individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must make the two datasets compatible. We discard features that don't apply to both rejected and accepted loan requests. We discard state information since the information is inherent in the zipcode data. Leaving the state information in would help us estimate predictions for datapoints in rare zipcodes, but will also tend to hide differences between zipcodes inside a given state, which we predict to be salient and useful. We represent the zipcodes as dummy variables to make sure we don't assume a linear relationship between zip code numbers. We discard the loan title, since no unified titling standard was used to help us easily compare different categories, and most titles are unique. We can also discard the policy code, since it's invariant across the rejected sample. We found no analogous field for risk/credit scores in the approved dataset, so we discard risk score. Hopefully debt-to-income ration would covariate and capture that information by proxy. While our dataset is limited and not fully similar in the range of dates, we can better extrapolate to dates not covered by the dataset by considering the seasonal trends divorced from specific years. Since one of our datasets does not provide exact dates, we only preserve the month the request was made. We also want to use the relationship between employment lengths for different applicants, without information on lengths shorter than a year or longer than 9. We approximate less than a year to a zero, and while the average employment length for applicants with 10 or more years of experience is probably much higher than 10, guessing a value would be risky and they are rare enough that we can safely set their employment length at 10 years.\n",
    "This leaves us with the features:\n",
    "- Amount Requested\n",
    "- Application Date (month*)\n",
    "- Debt-To-Income Ratio\n",
    "- Zip Code (as dummy variables)\n",
    "- Employment Length (0-10)\n",
    "\n",
    "*To best represent the cyclical nature of the yearly cycle, we convert the month values to two variables capturing sin and cos. This way Dec and Jan are as similar as Jan and Feb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Importing the datasets, erased first and last few unformatted rows manually, as well as 3 pesky empty rows\n",
    "#taking a subset of 3000 rejected examples to ease computation\n",
    "approved = pd.read_csv('LoanStats3A.csv')\n",
    "rejected = pd.read_csv('RejectStatsA.csv')\n",
    "rejected = rejected.iloc[:3000,:]\n",
    "#extracting relevant features\n",
    "rejected = rejected.iloc[:,[0,1,4,5,7]]\n",
    "approved = pd.concat([approved.iloc[:,2],approved.iloc[:,15],approved.iloc[:,24],approved.iloc[:,22],approved.iloc[:,11]],axis=1)\n",
    "rejected.columns=[\"loan_amnt\",\"issue_d\",\"dti\",\"zip_code\",\"emp_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>mcos</th>\n",
       "      <th>msin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>481xx</td>\n",
       "      <td>4 years</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>010xx</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>212xx</td>\n",
       "      <td>1 year</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>38.64</td>\n",
       "      <td>017xx</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>209xx</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt    dti zip_code emp_length      mcos  msin\n",
       "0     1000.0     10    481xx    4 years -0.866025   0.5\n",
       "1     1000.0     10    010xx   < 1 year -0.866025   0.5\n",
       "2    11000.0     10    212xx     1 year -0.866025   0.5\n",
       "3     6000.0  38.64    017xx   < 1 year -0.866025   0.5\n",
       "4     1500.0   9.43    209xx   < 1 year -0.866025   0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting dates to month variables\n",
    "months = pd.to_datetime(rejected['issue_d']).dt.strftime('%m').astype(float)\n",
    "msin=np.sin(2.*np.pi*months/12.).astype(float)\n",
    "mcos=np.cos(2.*np.pi*months/12.).astype(float)\n",
    "rejected.drop(['issue_d'],axis=1,inplace=True)\n",
    "rejected=pd.concat([rejected,pd.DataFrame({\"msin\":msin,\"mcos\":mcos})],axis=1)\n",
    "#converting dti\n",
    "rejected['dti'] = rejected['dti'].str.rstrip('%')\n",
    "rejected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>mcos</th>\n",
       "      <th>msin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>27.65</td>\n",
       "      <td>860xx</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>309xx</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>8.72</td>\n",
       "      <td>606xx</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>917xx</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>17.94</td>\n",
       "      <td>972xx</td>\n",
       "      <td>1 year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt    dti zip_code emp_length  mcos          msin\n",
       "0       5000  27.65    860xx  10+ years   1.0 -2.449294e-16\n",
       "1       2500   1.00    309xx   < 1 year   1.0 -2.449294e-16\n",
       "2       2400   8.72    606xx  10+ years   1.0 -2.449294e-16\n",
       "3      10000  20.00    917xx  10+ years   1.0 -2.449294e-16\n",
       "4       3000  17.94    972xx     1 year   1.0 -2.449294e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dates for accepted\n",
    "months = approved['issue_d']\n",
    "for index,date in months.iteritems():\n",
    "    if (str.startswith(date,\"7-\"))or(str.startswith(date,\"8-\"))or(str.startswith(date,\"9-\")):\n",
    "        months.set_value(index,\"0\"+date)\n",
    "months = pd.to_datetime(months,format=\"%y-%b\").dt.strftime(\"%m\").astype(float)\n",
    "msin=np.sin(2.*np.pi*months/12.).astype(float)\n",
    "mcos=np.cos(2.*np.pi*months/12.).astype(float)\n",
    "approved.drop(['issue_d'],axis=1,inplace=True)\n",
    "approved=pd.concat([approved,pd.DataFrame({\"msin\":msin,\"mcos\":mcos})],axis=1)\n",
    "approved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we can now combine the datasets and continue to process together, labeling approval as 1 and rejection as 0\n",
    "approved.insert(0, 'label', 1)\n",
    "rejected.insert(0, 'label', 0)\n",
    "data = pd.concat([approved,rejected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employment length has many n/a values. We could use mean imputation to approximate them, making the slightly precarious asssumption that missing values don't correlate with other observables in the data. We could also use expectation maximization to cluster them into 11 values (0-10) by approximation using similarity with labeled data. However, since an option for unemployed applicants is missing, it's likely that this is what ost n/a values in the data represent, so we'll be setting them to -1 to fit the relationship we've established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setting length to 0-10\n",
    "def emplength(x):\n",
    "    if \"<\" in x: return 0\n",
    "    elif \"/\" in x: return -1\n",
    "    else: return re.findall(\"\\d+\", x)[0]\n",
    "data['emp_length'] = data['emp_length'].astype(str).apply(emplength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>mcos</th>\n",
       "      <th>msin</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>17.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  loan_amnt    dti emp_length  mcos          msin  000  001  002  003  \\\n",
       "0      1     5000.0  27.65         10   1.0 -2.449294e-16  0.0  0.0  0.0  0.0   \n",
       "1      1     2500.0      1          0   1.0 -2.449294e-16  0.0  0.0  0.0  0.0   \n",
       "2      1     2400.0   8.72         10   1.0 -2.449294e-16  0.0  0.0  0.0  0.0   \n",
       "3      1    10000.0     20         10   1.0 -2.449294e-16  0.0  0.0  0.0  0.0   \n",
       "4      1     3000.0  17.94          1   1.0 -2.449294e-16  0.0  0.0  0.0  0.0   \n",
       "\n",
       "  ...   990  991  992  993  994  995  996  997  998  999  \n",
       "0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 1006 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting dummy variables for zip code\n",
    "data['zip_code']=data[\"zip_code\"].str.rstrip('xx')\n",
    "data = pd.concat([data,pd.get_dummies(data['zip_code'])],axis=1)\n",
    "data.drop(['zip_code'],axis=1,inplace=True)\n",
    "#attach yet-to-be-encountered dummies\n",
    "rang = [\"%03d\" % i for i in range(1000)]\n",
    "for ele in rang:\n",
    "    if ele not in data.columns:\n",
    "        spot=int(ele)+6\n",
    "        data.insert(spot,ele,0.)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data's processed, we can proceed with classification. I chose to try a new method to expand my horizons, and settled on the famed random forest bagging approach. It combines the decisions of multiple decision trees to reach an agreed conclusion, and preforms classification tasks well. It's important to scale our features before using Random Forests, to prevent the differnece in variance scales to let some features dominate over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11744222 -0.01575715 -0.72579424 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.38582524 -0.00884043  1.46192619 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.32538975 -0.01538826  0.64153103 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.78839976 -0.01653593 -0.99925929 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.4193238  -0.00964994  1.46192619 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.15094079 -0.00627868  0.09460092 ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Classification\n",
    "\n",
    "#Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,1:], data.iloc[:,0], test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train[:,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Approved       0.75      0.38      0.50       800\n",
      "   Rejected       0.95      0.99      0.97     10584\n",
      "\n",
      "avg / total       0.94      0.95      0.94     11384\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-26ac7f629c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Approved\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Rejected\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m std = np.std([classifier.feature_importances_ for tree in classifier.estimators_],\n\u001b[1;32m     21\u001b[0m              axis=0)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_n = {'n_estimators': [2, 5, 7]}\n",
    "classifier = GridSearchCV(RandomForestClassifier(), parameters_n,cv=3)\n",
    "\n",
    "#fitting\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Approved\",\"Rejected\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking (best 10):\n",
      "1. feature 1 (0.315340)\n",
      "2. feature 0 (0.144529)\n",
      "3. feature 2 (0.081250)\n",
      "4. feature 4 (0.055665)\n",
      "5. feature 3 (0.040443)\n",
      "6. feature 686 (0.003499)\n",
      "7. feature 305 (0.003331)\n",
      "8. feature 117 (0.003138)\n",
      "9. feature 307 (0.002967)\n",
      "10. feature 335 (0.002839)\n"
     ]
    }
   ],
   "source": [
    "#Feature importances\n",
    "importances = classifier.best_estimator_.feature_importances_\n",
    "std = np.std([classifier.best_estimator_.feature_importances_ for tree in classifier.best_estimator_.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking (best 10):\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Interestingly we see that the DTI ratio is more important than the loan amount. Now that we have an accurate model, we can use the predict function to find the highest loan amount a specific applicant can expect to get approved. We set the applicant's qualities arbitratily here, and iterate over the loan amount feature to find the classification boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes features except loan amount and a classifier and returns boundary for approval\n",
    "def approval_boundary(dti,zip_code,emp_length,month,clf,step=100,max_steps=1000):\n",
    "    #creates datapoint from features\n",
    "    x = np.zeros(1005)\n",
    "    x[1]=dti\n",
    "    x[2]=emp_length\n",
    "    x[3]=np.cos(2.*np.pi*month/12.).astype(float)\n",
    "    x[4]=np.sin(2.*np.pi*month/12.).astype(float)\n",
    "    x[zip_code+5]=1\n",
    "    #initalize loan amount \n",
    "    x[0]=50000\n",
    "    #feature scaling\n",
    "    [y] = sc.transform([x])\n",
    "    print[y]\n",
    "    if clf.predict([y])==0:\n",
    "        print(\"No chance!\")\n",
    "        return\n",
    "    #loop with increasing amount\n",
    "    for i in range(max_steps):\n",
    "        if clf.predict([y])==1:\n",
    "            x[0]+=step\n",
    "            [y] = sc.transform([x])\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Approval boundary: $\" + str(x[0]) + \" +/- $\" + str(step))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 5.25021802,  0.06187409, -0.99925929, ..., -0.02231675,\n",
      "       -0.01530714, -0.00541134])]\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "approval_boundary(80,300,1,12,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
